{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this challenge is to analyze a database sourced from [Chinese Real-Time Air Quality Monitoring Platform](http://106.37.208.233:20035/). Some cells are already implemented, you just need to **run** them. Some other cells need you to write some code.\n",
    "\n",
    "\n",
    "##### Agenda\n",
    "\n",
    "- Python 101\n",
    "- Your first Exploratory Data Analysis with Pandas, matplotlib and Seaborn\n",
    "\n",
    "We will code in a [Notebook](https://jupyter.org/).\n",
    "\n",
    "\n",
    "##### Here is a quick guide on how to use this Jupyter Notebook ü§î\n",
    "\n",
    "* Type inside the empty cells to write code. These empty cells will have a `In [ ]:` prefix before\n",
    "* Press the `return/enter ‚èé` key to add a new line inside the cell\n",
    "* To display your results use the Python built in `print(STUFF_YOU_WANT_TO_PRINT)` method or simply put the stuff you want to print as the last line inside the cell. The result of the last line will appear as the `Out[]:` or the output of the cell :)\n",
    "* Press `shift` + `return/enter ‚èé` to run your code ü§ì this will run the code inside your currently selected cell and print anything inside `print()` method and the last line of your cell\n",
    "* To add a new cell, select any cell and press the `b` key (make sure you are not just typing the letter `b` in the cell). This will add a new cell below\n",
    "* To delete a cell, double press the `d` key (make sure you are not just typing the letter `d` in the cell)\n",
    "\n",
    "##### Start the challenge by running the two following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need these libraries to run our analytics and visualisation\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will read the CSV file into a DataFrame - the format that we can easily analyze and manipulate\n",
    "# For example, the original datasets we extract from the Chinese official website\n",
    "raw_df = pd.read_csv('data/rawdatasets/city_AQI/city_2020/china_cities_20201121.csv', decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëÄ Feel free to have a quick glance at the data - `.shape`, `.columns`, `.head()`, `.tail()`, `.dtypes` \n",
    "<br>\n",
    "\n",
    "<details>\n",
    "    <summary>Not sure how? Reveal some tips üôà</summary>\n",
    "\n",
    "<p> \n",
    "<pre>\n",
    "raw_df.shape\n",
    "raw_df.columns\n",
    "raw_df.head() # you can add a number in parentheses for how many first rows you want to display\n",
    "raw_df.dtypes\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëÄ  Air quality data acquired at official monitoring stations nationwide. \n",
    "The level of six atmospheric pollutants was reported hourly, and each time an [Air Quality Index (AQI)](https://en.wikipedia.org/wiki/Air_quality_index) would be calculated based on these pollutants data. \n",
    "\n",
    "The six atmospheric pollutants include sulfur dioxide ($\\rm SO_2$), nitrogen dioxide ($\\rm NO_2$), particular matters smaller than 10 $\\mu m$ in aerodynamic diameter ($\\mathrm{PM_{10}}$), particular matters smaller than 2.5 $\\mu m$ ($\\rm PM_{2.5}$), carbon monoxide (CO), and ozone ($\\rm O_3$). \n",
    "\n",
    "An individual score is assigned to each pollutant and the final AQI is the highest of these six scores.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('data/measurement_item_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', items.shape)\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing data and creating auxiliar structures\n",
    "\n",
    "Data preprocessing usually takes most the time in a project. According to CrowdFlower 2016 report, data scientists in average take 60% of their time to clean and organise data. For our limited time in this session, we have a pre-processed dataframe for you already (We translated the name of the city stations from Chinese to English, extracted only part of the pollutant readings, and put the daily recording of almost three years into a single [pickle](https://docs.python.org/3/library/pickle.html#data-stream-format) file.\n",
    "\n",
    "Now we will read the pickle file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df = pd.read_pickle('data/pollutants6_2018-current.pkl', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To examine the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We still have some cleaning to do on our DataFrame.__ üßπ \n",
    "\n",
    "First of all, let's extract only AQI data from the master dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__There are missing timestamps in your dataframe. Before moving to further analysis, shall we fill them up with NaN (not a number) so that our dataframe will have a continuous hourly reading.__  \n",
    "\n",
    "<details>\n",
    "    <summary>Not sure how? Reveal some tips üôà</summary>\n",
    "\n",
    "<p> \n",
    "<pre>\n",
    "idx = pd.date_range(min(AQI_df.index), max(AQI_df.index), freq='h')\n",
    "AQI_df.reindex(idx, fill_value=np.nan)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Let's focus on only 5 cities\n",
    "\n",
    "So pick up 5 cities of your interest. Write them into a python list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extract AQI data for your chosen cities from the AQI master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling missing Data\n",
    "\n",
    "There are a few missing data in the AQI readings for each city. You can see it as NaN (not a number) in the dataframe. In the wild, of course, you will experience missing data in different representations. The reasons for missing data might be failure of measurement or programming error. Sometimes, you can simply drop these missing data if they appear unnecessary BUT in this case we want to keep a uniform timestamp and hence we will impute a value to it.\n",
    "\n",
    "It needs thorough consideration to choose an imputer or write your own imputing programme. This concept may be a bit too advanced to put here. Therefore, we will have the answers ready for you to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are missing AQI values for different locations. Can you see how many of them in total for each city?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the time series nature of our data, we will use a time interpolation imputer coded as below. Now try to apply it to your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_interpolation_impute(df):\n",
    "    cities = df.columns.unique()\n",
    "    for city in cities:\n",
    "        if city !='index' and city != 'date' and city != 'hour' and city != 'type':\n",
    "            if df[city].isnull().sum() > 0:\n",
    "                df[city].interpolate(method='time', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create visulisations to have an overview on the trend of pollution levels varing with time\n",
    "\n",
    "As it's probably new to you, let's try a single lineplot first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dataframe name to your own.\n",
    "x = myAQI_df.index\n",
    "y = myAQI_df['Shanghai']\n",
    "\n",
    "plt.plot(x, y, 'g-', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot trends for all 5 cities. You can use [subplots](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.subplots.html) for a neat presentation. \n",
    "\n",
    "<details>\n",
    "    <summary>Hint:</summary>\n",
    "\n",
    "<p> \n",
    "<pre>\n",
    "Try sns.lineplot for the seaborn library.\n",
    "\n",
    "You can plot for each city individually or use plt.subplots to put them neatly together.\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The percentage of the severely polluted hours \n",
    "\n",
    "As we can see above, AQI values change over the location and along the time. AQI tells the level of pollution. In China, six categories ranging from Excellent to Severely Polluted have been designed based on the AQI values.\n",
    "\n",
    "##### Binning\n",
    "Here, we want to categorize the AQI values into the 6 levels and visulize them in a bar chart to see the percentage of 'bad' days in the 5 cities, respectively.\n",
    "\n",
    "üëá Using Panda's `cut` ([doc](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html)), for each city, bin the data into:\n",
    "    - Excellent (AQI 0 to 50 included)\n",
    "    - Good (51 to 100 included)\n",
    "    - Lightly Polluted (101 to 150 included)\n",
    "    - Moderately Polluted (151 to 200 included)\n",
    "    - Heavily Polluted (201 to 300 included)\n",
    "    - Severely Polluted (300 and above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Bar chart to see the counts of each pollution level along the past three years.\n",
    "\n",
    "Using Panda's `value_counts`([doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.value_counts.html)), count the number of appearance of each pollution level for every city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pollutant Distribution on Map\n",
    "\n",
    "Reported concentrations of pollutants can vary depending on the location. In order to have a better overview of the pollutant forming and movement, we will use geological info to map the pollutant levels to their stations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the PM2.5 measurement from the air_df and create a working dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an external dataset containing the geometry data for these measuring stations\n",
    "geo = pd.read_csv('data/geo_distance.csv')\n",
    "geo.set_index('city', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the stations using plotly package\n",
    "import plotly.express as px\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can even visulise the transport of the pollutants over the time and space using plotly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One month data only, considering the computational time. Let's take last December as an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with geo dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the motion pictures using plotly.express.density_mapbox\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
